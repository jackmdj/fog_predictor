{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 62.0000,  72.3600,  53.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 62.0000,  72.3600,  53.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 62.0000,  72.3600,  53.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 54.0000,  93.6000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 54.0000,  93.6000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 54.0000,  93.6000,  51.0000,   1.0000],\n",
      "        [ 54.0000,  93.6000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 54.0000,  93.6000,  51.0000,   1.0000],\n",
      "        [ 54.0000,  93.6000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 62.0000,  72.3600,  53.0000,   1.0000],\n",
      "        [ 62.0000,  72.3600,  53.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   0.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 62.0000,  72.3600,  53.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000],\n",
      "        [ 52.0000, 100.0000,  51.0000,   1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = 'C:\\\\Users\\\\jackm\\\\Desktop\\\\projects\\\\fog_predictor\\\\weather_data.csv'\n",
    "data = pd.read_csv(data_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Update the 'Fog' column based on dates\n",
    "data['Fog'] = data['Observation Time'].apply(lambda x: 1 if '2024-05-11' in x else 0)\n",
    "\n",
    "# Convert features\n",
    "data['Temperature'] = data['Temperature'].str.extract(r'(\\d+)').astype(float)\n",
    "data['Dew Point'] = data['Dew Point'].str.extract(r'(\\d+)').astype(float)\n",
    "data['Humidity'] = data['Humidity'].str.replace('%', '').astype(float)\n",
    "\n",
    "# Encode categorical data\n",
    "trend_mapping = {'rising': 1, 'falling': 0}  # Example encoding\n",
    "data['Trend'] = data['Trend'].map(trend_mapping).astype(float)\n",
    "\n",
    "# Shuffle the data\n",
    "data = data.sample(frac=1, random_state=420).reset_index(drop=True)\n",
    "\n",
    "# Prepare feature tensor and labels\n",
    "features = torch.tensor(data[['Temperature', 'Humidity', 'Dew Point', 'Trend']].values, dtype=torch.float32)\n",
    "labels = torch.tensor(data['Fog'].values, dtype=torch.float32)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "features, labels = features[~torch.isnan(features).any(dim=1)], labels[~torch.isnan(features).any(dim=1)]\n",
    "\n",
    "# Split data into train and test\n",
    "train_features = features[:int(0.8 * len(features))]\n",
    "test_features = features[int(0.8 * len(features)):]\n",
    "train_labels = labels[:int(0.8 * len(labels))]\n",
    "test_labels = labels[int(0.8 * len(labels)):]\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(4, 10),  # 4 features to 10 hidden nodes\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()  # Output a single probability for binary classification\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = MLP()\n",
    "loss_function = nn.BCELoss()  # Binary cross-entropy loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3386991024017334\n",
      "Epoch 101, Loss: 0.6372416615486145\n",
      "Epoch 201, Loss: 0.540835976600647\n",
      "Epoch 301, Loss: 0.4577319025993347\n",
      "Epoch 401, Loss: 0.43126165866851807\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "def train(model, features, labels, optimizer, loss_function, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(features)\n",
    "        loss = loss_function(predictions.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Run training\n",
    "train(model, train_features, train_labels, optimizer, loss_function, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n",
      "Precision: 0.8571428571428571\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9230769230769231\n",
      "ROC AUC: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_features, test_labels):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        predictions = model(test_features).squeeze()\n",
    "        # Convert probabilities to binary output\n",
    "        predicted_classes = (predictions > 0.5).float()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(test_labels, predicted_classes)\n",
    "        precision = precision_score(test_labels, predicted_classes)\n",
    "        recall = recall_score(test_labels, predicted_classes)\n",
    "        f1 = f1_score(test_labels, predicted_classes)\n",
    "        roc_auc = roc_auc_score(test_labels, predictions)  # Use probabilities for ROC AUC\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\nROC AUC: {roc_auc}\")\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_model(model, test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mlp_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
