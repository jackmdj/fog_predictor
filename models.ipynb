{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(loader):\n",
    "    # Variances and means across channels\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    nb_samples = 0\n",
    "    \n",
    "    # Calculate mean\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "    \n",
    "    mean /= nb_samples\n",
    "    \n",
    "    # Calculate std\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        std += ((images - mean.unsqueeze(1))**2).mean(2).sum(0)\n",
    "    \n",
    "    std = torch.sqrt(std / nb_samples)\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcNormalization(batch_size):\n",
    "    # Define transformations, adjust according to your need\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize all images to 256x256\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    ])\n",
    "\n",
    "    # Get the path to the current working directory\n",
    "    base_dir = os.getcwd()\n",
    "    # Append subdirectory to the base path\n",
    "    train_path = os.path.join(base_dir, 'ImageData', 'train')\n",
    "\n",
    "    # Loading the training data\n",
    "    train_data = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    mean, sd = calculate_mean_std(train_loader)\n",
    "    return mean, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, sd = calcNormalization(22)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize all images to 256x256\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=mean.tolist(), std=sd.tolist())\n",
    "])\n",
    "\n",
    "# Get the path to the current working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# Append subdirectory to the base path\n",
    "train_path = os.path.join(base_dir, 'ImageData', 'train')\n",
    "test_path = os.path.join(base_dir, 'ImageData', 'test')\n",
    "\n",
    "# Loading the training data\n",
    "train_data = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=22, shuffle=True)\n",
    "\n",
    "# Loading the test data\n",
    "test_data = datasets.ImageFolder(root=test_path, transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet18 model\n",
    "model = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in your dataset\n",
    "# Assuming binary classification ('fog' vs 'no fog')\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Move the model to the chosen device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7952215075492859\n",
      "Epoch 2, Loss: 0.4027418717741966\n",
      "Epoch 3, Loss: 0.17285812832415104\n",
      "Epoch 4, Loss: 0.0695514502003789\n",
      "Epoch 5, Loss: 0.08738197665661573\n",
      "Epoch 6, Loss: 0.0600759694352746\n",
      "Epoch 7, Loss: 0.027829045429825783\n",
      "Epoch 8, Loss: 0.03515626955777407\n",
      "Epoch 9, Loss: 0.01605488103814423\n",
      "Epoch 10, Loss: 0.01307328708935529\n",
      "Epoch 11, Loss: 0.012126151588745415\n",
      "Epoch 12, Loss: 0.009101885952986777\n"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 12\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):  # num_epochs should be set by you\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "[[5 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    y_pred.extend(predicted.cpu().numpy())\n",
    "    y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
