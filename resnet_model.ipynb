{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(loader):\n",
    "    # Variances and means across channels\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    nb_samples = 0\n",
    "    \n",
    "    # Calculate mean\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "    \n",
    "    mean /= nb_samples\n",
    "    \n",
    "    # Calculate std\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        std += ((images - mean.unsqueeze(1))**2).mean(2).sum(0)\n",
    "    \n",
    "    std = torch.sqrt(std / nb_samples)\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcNormalization(batch_size):\n",
    "    # Define transformations, adjust according to your need\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize all images to 256x256\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    ])\n",
    "\n",
    "    # Get the path to the current working directory\n",
    "    base_dir = os.getcwd()\n",
    "    # Append subdirectory to the base path\n",
    "    train_path = os.path.join(base_dir, 'ImageData', 'train')\n",
    "\n",
    "    # Loading the training data\n",
    "    train_data = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    mean, sd = calculate_mean_std(train_loader)\n",
    "    return mean, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, sd = calcNormalization(1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize all images to 256x256\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=mean.tolist(), std=sd.tolist())\n",
    "])\n",
    "\n",
    "# Get the path to the current working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# Append subdirectory to the base path\n",
    "train_path = os.path.join(base_dir, 'ImageData', 'train')\n",
    "test_path = os.path.join(base_dir, 'ImageData', 'test')\n",
    "\n",
    "# Loading the training data\n",
    "train_data = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=22, shuffle=True)\n",
    "\n",
    "# Loading the test data\n",
    "test_data = datasets.ImageFolder(root=test_path, transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-2.0225, -2.0385, -1.9271,  ..., -1.8475, -1.7520, -1.8316],\n",
      "         [-2.0544, -1.9907, -1.8952,  ..., -1.8634, -1.7679, -1.7998],\n",
      "         [-1.4656, -1.2746, -1.1155,  ..., -1.8793, -1.8475, -1.7679],\n",
      "         ...,\n",
      "         [-1.7838, -1.6247, -1.6406,  ..., -1.9589, -1.9271, -1.9748],\n",
      "         [-1.7520, -1.6565, -1.6406,  ..., -1.9907, -1.9907, -1.9430],\n",
      "         [-1.7520, -1.7838, -1.8316,  ..., -2.0225, -1.9907, -1.9748]],\n",
      "\n",
      "        [[-2.0314, -2.0474, -1.9351,  ..., -1.8548, -1.7586, -1.8388],\n",
      "         [-2.0635, -1.9993, -1.9030,  ..., -1.8709, -1.7746, -1.8067],\n",
      "         [-1.4697, -1.2772, -1.1167,  ..., -1.8869, -1.8548, -1.7746],\n",
      "         ...,\n",
      "         [-1.7907, -1.6302, -1.6462,  ..., -1.9672, -1.9351, -1.9832],\n",
      "         [-1.7586, -1.6623, -1.6462,  ..., -1.9993, -1.9993, -1.9511],\n",
      "         [-1.7586, -1.7907, -1.8388,  ..., -2.0314, -1.9993, -1.9832]],\n",
      "\n",
      "        [[-1.9997, -2.0152, -1.9068,  ..., -1.8293, -1.7364, -1.8138],\n",
      "         [-2.0307, -1.9687, -1.8758,  ..., -1.8448, -1.7519, -1.7828],\n",
      "         [-1.4576, -1.2717, -1.1168,  ..., -1.8603, -1.8293, -1.7519],\n",
      "         ...,\n",
      "         [-1.7674, -1.6125, -1.6280,  ..., -1.9377, -1.9068, -1.9532],\n",
      "         [-1.7364, -1.6434, -1.6280,  ..., -1.9687, -1.9687, -1.9223],\n",
      "         [-1.7364, -1.7674, -1.8138,  ..., -1.9997, -1.9687, -1.9532]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet18 model\n",
    "model = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in your dataset\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Move the model to the chosen device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5716857686638832\n",
      "Epoch 2, Loss: 0.30265215784311295\n",
      "Epoch 3, Loss: 0.18266824260354042\n",
      "Epoch 4, Loss: 0.12496978044509888\n",
      "Epoch 5, Loss: 0.07081027328968048\n",
      "Epoch 6, Loss: 0.04670743551105261\n",
      "Epoch 7, Loss: 0.03066325467079878\n",
      "Epoch 8, Loss: 0.05198593670502305\n",
      "Epoch 9, Loss: 0.05561822606250644\n",
      "Epoch 10, Loss: 0.016229575034230947\n",
      "Epoch 11, Loss: 0.018644500290974975\n",
      "Epoch 12, Loss: 0.014191812137141824\n"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 12\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):  # num_epochs should be set by you\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "[[5 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    y_pred.extend(predicted.cpu().numpy())\n",
    "    y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'image_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
